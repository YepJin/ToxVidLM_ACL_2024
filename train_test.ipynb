{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e8c787",
   "metadata": {},
   "source": [
    "# Some preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bd3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ToxVidLM_ACL_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38134eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4369ed7",
   "metadata": {},
   "source": [
    "## Packages Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e48f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.0 (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.1 (from -r requirements.txt (line 2))\n",
      "  Downloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting torchaudio==2.0.1 (from -r requirements.txt (line 3))\n",
      "  Downloading torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting librosa==0.10.1 (from -r requirements.txt (line 4))\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting av==10.0.0 (from -r requirements.txt (line 5))\n",
      "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting Pillow==10.0.1 (from -r requirements.txt (line 7))\n",
      "  Downloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting tqdm==4.66.1 (from -r requirements.txt (line 8))\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy==1.24.4 (from -r requirements.txt (line 9))\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas==2.0.3 (from -r requirements.txt (line 10))\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 11))\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pytorchvideo==0.1.5 (from -r requirements.txt (line 12))\n",
      "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==4.35.2 (from -r requirements.txt (line 13))\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Collecting datasets==2.14.6 (from -r requirements.txt (line 14))\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate==0.4.1 (from -r requirements.txt (line 15))\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting filelock (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting sympy (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jinja2 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting requests (from torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting joblib>=0.14 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.0.3->-r requirements.txt (line 10))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.0.3->-r requirements.txt (line 10))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.3.2->-r requirements.txt (line 11))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fvcore (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting parameterized (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting iopath (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyarrow>=8.0.0 (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting xxhash (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multiprocess-0.70.18-py38-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->-r requirements.txt (line 15))\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (75.3.0)\n",
      "Requirement already satisfied: wheel in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (0.45.1)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in ./.conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (8.5.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 10)) (1.16.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting termcolor>=1.1 (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tabulate (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting portalocker (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multiprocess-0.70.17-py38-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.conda/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (3.21.0)\n",
      "Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
      "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.5/746.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
      "Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
      "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188686 sha256=29f5d0a7bef16f4bcb3cdb724c000b405ede5a2296fbf0f90e0d7bfca2562bf8\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/62/e5/0b41f2deb978f449ba3efb4bb24efd6962e4b6abb1fae544ee\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61398 sha256=e272e7923cec1ce37780272c0a81d5267c84099f8b5ab644f00e956e4e520575\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=02ca7234796b98db8b0507c61dc33f76de5e346769d2619daa9802b151dbf9e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
      "Successfully built pytorchvideo fvcore iopath\n",
      "Installing collected packages: pytz, mpmath, lit, av, xxhash, urllib3, tzdata, tqdm, threadpoolctl, termcolor, tabulate, sympy, safetensors, regex, pyyaml, pycparser, propcache, portalocker, Pillow, parameterized, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, msgpack, MarkupSafe, llvmlite, lazy-loader, joblib, idna, hf-xet, fsspec, frozenlist, filelock, dill, cmake, charset_normalizer, certifi, audioread, attrs, async-timeout, aiohappyeyeballs, yarl, yacs, soxr, scipy, requests, pyarrow, pandas, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, numba, multiprocess, jinja2, iopath, cffi, aiosignal, soundfile, scikit-learn, responses, pooch, huggingface-hub, fvcore, aiohttp, tokenizers, pytorchvideo, librosa, transformers, datasets, evaluate, triton, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.0.1 aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 attrs-25.3.0 audioread-3.0.1 av-10.0.0 certifi-2025.7.14 cffi-1.17.1 charset_normalizer-3.4.2 cmake-4.0.3 datasets-2.14.6 dill-0.3.7 evaluate-0.4.1 filelock-3.16.1 frozenlist-1.5.0 fsspec-2023.10.0 fvcore-0.1.5.post20221221 hf-xet-1.1.5 huggingface-hub-0.34.1 idna-3.10 iopath-0.1.10 jinja2-3.1.6 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.1 lit-18.1.8 llvmlite-0.41.1 mpmath-1.3.0 msgpack-1.1.1 multidict-6.1.0 multiprocess-0.70.15 networkx-3.1 numba-0.58.1 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.8.1.78 pandas-2.0.3 parameterized-0.9.0 pooch-1.8.2 portalocker-3.0.0 propcache-0.2.0 pyarrow-17.0.0 pycparser-2.22 pytorchvideo-0.1.5 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 responses-0.18.0 safetensors-0.5.3 scikit-learn-1.3.2 scipy-1.10.1 soundfile-0.13.1 soxr-0.3.7 sympy-1.13.3 tabulate-0.9.0 termcolor-2.4.0 threadpoolctl-3.5.0 tokenizers-0.15.2 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 tqdm-4.66.1 transformers-4.35.2 triton-2.0.0 tzdata-2025.2 urllib3-2.2.3 xxhash-3.5.0 yacs-0.1.8 yarl-1.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212194fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft==0.6.2\n",
      "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (25.0)\n",
      "Requirement already satisfied: psutil in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (2.0.0)\n",
      "Requirement already satisfied: transformers in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (4.35.2)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (4.66.1)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.6.2)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.conda/lib/python3.8/site-packages (from accelerate>=0.21.0->peft==0.6.2) (0.34.1)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.2) (75.3.0)\n",
      "Requirement already satisfied: wheel in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.2) (0.45.1)\n",
      "Requirement already satisfied: cmake in ./.conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.6.2) (4.0.3)\n",
      "Requirement already satisfied: lit in ./.conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.6.2) (18.1.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (0.15.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.21.0->peft==0.6.2) (2023.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.21.0->peft==0.6.2) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft==0.6.2) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft==0.6.2) (1.3.0)\n",
      "Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.0.1 peft-0.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5468d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: backcall in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7282c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.0\n",
      "Uninstalling torch-2.0.0:\n",
      "  Successfully uninstalled torch-2.0.0\n",
      "Found existing installation: torchvision 0.15.1\n",
      "Uninstalling torchvision-0.15.1:\n",
      "  Successfully uninstalled torchvision-0.15.1\n",
      "Found existing installation: torchaudio 2.0.1\n",
      "Uninstalling torchaudio-2.0.1:\n",
      "  Successfully uninstalled torchaudio-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu102\n",
      "Collecting torch==1.12.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.13.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.13.1%2Bcu102-cp38-cp38-linux_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.12.1\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchaudio-0.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch==1.12.1+cu102) (4.12.2)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (1.24.4)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (2.32.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (10.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2025.7.14)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.6.2 requires torch>=1.13.0, but you have torch 1.12.1+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.12.1+cu102 torchaudio-0.12.1+cu102 torchvision-0.13.1+cu102\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCUDA available: True\n",
      "CUDA version: 11.7\n",
      "PyTorch version: 2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "# Add this cell before the train cell\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu102\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77d83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 10.2\n",
      "PyTorch version: 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a3574",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gdown first\n",
    "!pip install gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793bc3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4242053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For a public folder, you can try:\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create download directory\n",
    "os.makedirs(\"g_downloaded_data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acde4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"final_data/\" >> .gitignore\n",
    "!echo \"g_downloaded_data/\" >> .gitignore\n",
    "!echo \"downloaded_data/\" >> .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz classification_final_data-20250630T215505Z-1-001.zip\n",
      "Processing file 1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX classification_final_data-20250630T215505Z-1-002.zip\n",
      "Processing file 1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46 classification_final_data-20250630T215505Z-1-003.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz\n",
      "From (redirected): https://drive.google.com/uc?id=1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz&confirm=t&uuid=d8cf1231-a1b8-47db-98c7-87ec33f3444b\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip\n",
      "100%|██████████| 2.15G/2.15G [02:52<00:00, 12.5MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX\n",
      "From (redirected): https://drive.google.com/uc?id=1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX&confirm=t&uuid=df5ed501-d21b-4124-8f23-99997f848f18\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip\n",
      "100%|██████████| 2.15G/2.15G [02:51<00:00, 12.5MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46\n",
      "From (redirected): https://drive.google.com/uc?id=1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46&confirm=t&uuid=fb12d525-4d7e-4462-8dcb-cdbaad4e0c15\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip\n",
      "100%|██████████| 1.65G/1.65G [02:08<00:00, 12.8MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip',\n",
       " 'g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip',\n",
       " 'g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download the entire folder (this works for some public folders)\n",
    "folder_id = \"1fddccfJkYZifbRF9zrhYlmX4IAMICnwb\"\n",
    "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=\"g_downloaded_data/\", quiet=False, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip...\n",
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip...\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "download_dir = \"g_downloaded_data/ToxVid\"\n",
    "# List all files in the download directory\n",
    "for filename in os.listdir(download_dir):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(download_dir, filename)\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(download_dir)      \n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv g_downloaded_data/ToxVid/classification_final_data final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acafed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_folder = \"final_data/classification_final_data\"\n",
    "destination_folder = \"final_data\"\n",
    "\n",
    "# Check if source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # List all files in the source folder\n",
    "    files = os.listdir(source_folder)\n",
    "    \n",
    "    # Move each file to the destination folder\n",
    "    for file in files:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(destination_folder, file)\n",
    "        shutil.move(source_path, destination_path)\n",
    "    \n",
    "    print(\"Files moved successfully.\")\n",
    "else:\n",
    "    print(\"Source folder does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09f3d3",
   "metadata": {},
   "source": [
    "# Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa13638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'final_data/' did not match any files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'g_downloaded_data/' did not match any files\n",
      "fatal: pathspec 'downloaded_data/' did not match any files\n"
     ]
    }
   ],
   "source": [
    "# Remove folders from Git tracking (but keep them locally)\n",
    "!git rm -r --cached final_data/\n",
    "!git rm -r --cached g_downloaded_data/\n",
    "!git rm -r --cached downloaded_data/\n",
    "!git rm -r --cached data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9917f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 521de73] Add data folders to .gitignore\n",
      " 3 files changed, 878 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " delete mode 100644 final_data/final_data.txt.txt\n",
      " create mode 100644 train_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Add the .gitignore changes\n",
    "!git add .gitignore\n",
    "\n",
    "# Commit the changes\n",
    "!git commit -m \"Add data folders to .gitignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Your descriptive commit message\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7529a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92235938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b15cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA memory allocation configuration to reduce fragmentation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5422f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# From train.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\"\n",
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_data/final_processed_data_one_hot.csv\")\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.4, random_state=28703)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.4, random_state=28703)\n",
    "\n",
    "num_epochs = 1\n",
    "patience = 10\n",
    "batch_size = 2\n",
    "\n",
    "#for roberta\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"l3cube-pune/hing-roberta\")\n",
    "model = XLMRobertaModel.from_pretrained(\"l3cube-pune/hing-roberta\", torch_dtype=torch.float32)\n",
    "\n",
    "\n",
    "model = Multimodal_LLM(batch_size=batch_size, config=config, tokenizer=tokenizer, adapter_llm=model)\n",
    "\n",
    "train_ds = CustomDataset(dataframe=df_train, train=True, tokenizer=tokenizer)\n",
    "val_ds = CustomDataset(df_val, train=True, tokenizer=tokenizer)\n",
    "test_ds = CustomDataset(df_test, train=False, tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea3dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1 out of 2\n",
      "  0%|                                                   | 0/724 [00:00<?, ?it/s]thread '<unnamed>' panicked at /root/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rayon-core-1.12.1/src/registry.rs:168:10:\n",
      "The global thread pool has not been initialized.: ThreadPoolBuildError { kind: IOError(Os { code: 11, kind: WouldBlock, message: \"Resource temporarily unavailable\" }) }\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n",
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/data/dataset.py\", line 83, in __getitem__\n",
      "    sample = prepare_batch(batch=sample, tokenizer=self.tokenizer)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/data/utils.py\", line 148, in prepare_batch\n",
      "    tokenized_text = tokenizer(dialogue, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_len-3, add_special_tokens=False)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2798, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2904, in _call_one\n",
      "    return self.encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2977, in encode_plus\n",
      "    return self._encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\", line 576, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\", line 504, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "pyo3_runtime.PanicException: The global thread pool has not been initialized.: ThreadPoolBuildError { kind: IOError(Os { code: 11, kind: WouldBlock, message: \"Resource temporarily unavailable\" }) }\n",
      "  0%|                                                   | 0/724 [00:07<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 506056) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 113, in <module>\n",
      "    train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 85, in train_model\n",
      "    train_loss = train_one_epoch(model, train_dataloader, optimizer, config)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 15, in train_one_epoch\n",
      "    for batch in tqdm(train_dataloader):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n",
      "RuntimeError: DataLoader worker (pid(s) 506056) exited unexpectedly\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0505f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Traceback (most recent call last):\n",
      "  File \"test.py\", line 112, in <module>\n",
      "    state_dict = torch.load(checkpoint_path, map_location=config.device)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 791, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 271, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 252, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/model_save.pth'\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331bf53",
   "metadata": {},
   "source": [
    "# For debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23a680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared. Available: 34072559616 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"GPU memory cleared. Available: {torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9565f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\"\n",
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10076c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save_path = config.results_directory + config.file_name + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "history={\"a\":\"b\"}\n",
    "with open(json_save_path, 'w') as json_file:\n",
    "    json.dump(history, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was cleaned up - the train_model function is already imported from iteration.py\n",
    "# No need to redefine it here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
