{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e8c787",
   "metadata": {},
   "source": [
    "# Some preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bd3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ToxVidLM_ACL_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38134eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4369ed7",
   "metadata": {},
   "source": [
    "## Packages Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e48f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.0 (from -r requirements.txt (line 1))\n",
      "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.1 (from -r requirements.txt (line 2))\n",
      "  Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting torchaudio==2.0.1 (from -r requirements.txt (line 3))\n",
      "  Using cached torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: librosa==0.10.1 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: av==10.0.0 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (10.0.0)\n",
      "Requirement already satisfied: opencv-python==4.8.1.78 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (4.8.1.78)\n",
      "Requirement already satisfied: Pillow==10.0.1 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (10.0.1)\n",
      "Requirement already satisfied: tqdm==4.66.1 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (4.66.1)\n",
      "Requirement already satisfied: numpy==1.24.4 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.24.4)\n",
      "Requirement already satisfied: pandas==2.0.3 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn==1.3.2 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: pytorchvideo==0.1.5 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.1.5)\n",
      "Requirement already satisfied: transformers==4.35.2 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (4.35.2)\n",
      "Requirement already satisfied: datasets==2.14.6 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (2.14.6)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /workspace/.conda/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.4.1)\n",
      "Requirement already satisfied: filelock in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /workspace/.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (11.7.91)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: requests in /workspace/.conda/lib/python3.8/site-packages (from torchvision==0.15.1->-r requirements.txt (line 2)) (2.32.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /workspace/.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.conda/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.conda/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspace/.conda/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /workspace/.conda/lib/python3.8/site-packages (from scikit-learn==1.3.2->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: fvcore in /workspace/.conda/lib/python3.8/site-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 12)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: parameterized in /workspace/.conda/lib/python3.8/site-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: iopath in /workspace/.conda/lib/python3.8/site-packages (from pytorchvideo==0.1.5->-r requirements.txt (line 12)) (0.1.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (0.34.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /workspace/.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /workspace/.conda/lib/python3.8/site-packages (from datasets==2.14.6->-r requirements.txt (line 14)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /workspace/.conda/lib/python3.8/site-packages (from datasets==2.14.6->-r requirements.txt (line 14)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /workspace/.conda/lib/python3.8/site-packages (from datasets==2.14.6->-r requirements.txt (line 14)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /workspace/.conda/lib/python3.8/site-packages (from datasets==2.14.6->-r requirements.txt (line 14)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /workspace/.conda/lib/python3.8/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6->-r requirements.txt (line 14)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /workspace/.conda/lib/python3.8/site-packages (from datasets==2.14.6->-r requirements.txt (line 14)) (3.10.11)\n",
      "Requirement already satisfied: responses<0.19 in /workspace/.conda/lib/python3.8/site-packages (from evaluate==0.4.1->-r requirements.txt (line 15)) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /workspace/.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (75.3.0)\n",
      "Requirement already satisfied: wheel in /workspace/.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (0.45.1)\n",
      "Requirement already satisfied: cmake in /workspace/.conda/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1)) (4.0.3)\n",
      "Requirement already satisfied: lit in /workspace/.conda/lib/python3.8/site-packages (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1)) (18.1.8)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /workspace/.conda/lib/python3.8/site-packages (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (5.0.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /workspace/.conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 13)) (1.1.5)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /workspace/.conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /workspace/.conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (8.5.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /workspace/.conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (2025.7.14)\n",
      "Requirement already satisfied: cffi>=1.0 in /workspace/.conda/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4)) (1.17.1)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /workspace/.conda/lib/python3.8/site-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12)) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /workspace/.conda/lib/python3.8/site-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12)) (2.4.0)\n",
      "Requirement already satisfied: tabulate in /workspace/.conda/lib/python3.8/site-packages (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /workspace/.conda/lib/python3.8/site-packages (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.conda/lib/python3.8/site-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.conda/lib/python3.8/site-packages (from sympy->torch==2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /workspace/.conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4)) (2.22)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspace/.conda/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.14.6->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /workspace/.conda/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (3.21.0)\n",
      "Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "Using cached torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "Installing collected packages: triton, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "Successfully installed torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install peft==0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5468d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling torch-2.0.0:\n",
      "  Successfully uninstalled torch-2.0.0\n",
      "Found existing installation: torchvision 0.15.1\n",
      "Uninstalling torchvision-0.15.1:\n",
      "  Successfully uninstalled torchvision-0.15.1\n",
      "Found existing installation: torchaudio 2.0.1\n",
      "Uninstalling torchaudio-2.0.1:\n",
      "  Successfully uninstalled torchaudio-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu102\n",
      "Collecting torch==1.12.1+cu102\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torch-1.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (776.3 MB)\n",
      "Collecting torchvision==0.13.1+cu102\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchvision-0.13.1%2Bcu102-cp38-cp38-linux_x86_64.whl (19.1 MB)\n",
      "Collecting torchaudio==0.12.1\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchaudio-0.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (3.7 MB)\n",
      "Requirement already satisfied: typing-extensions in /workspace/.conda/lib/python3.8/site-packages (from torch==1.12.1+cu102) (4.12.2)\n",
      "Requirement already satisfied: numpy in /workspace/.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (1.24.4)\n",
      "Requirement already satisfied: requests in /workspace/.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (2.32.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (10.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2025.7.14)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.6.2 requires torch>=1.13.0, but you have torch 1.12.1+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.12.1+cu102 torchaudio-0.12.1+cu102 torchvision-0.13.1+cu102\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCUDA available: True\n",
      "CUDA version: 11.7\n",
      "PyTorch version: 2.0.0+cu117\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c77d83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 10.2\n",
      "PyTorch version: 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a3574",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gdown first\n",
    "!pip install gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793bc3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4242053",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir downloaded_data\n",
    "\n",
    "# For a public folder, you can try:\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create download directory\n",
    "os.makedirs(\"g_downloaded_data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acde4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"final_data/\" >> .gitignore\n",
    "!echo \"g_downloaded_data/\" >> .gitignore\n",
    "!echo \"downloaded_data/\" >> .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da0249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz classification_final_data-20250630T215505Z-1-001.zip\n",
      "Processing file 1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX classification_final_data-20250630T215505Z-1-002.zip\n",
      "Processing file 1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46 classification_final_data-20250630T215505Z-1-003.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz\n",
      "From (redirected): https://drive.google.com/uc?id=1Tj31_sm-gLGVtr5ZeqGnmfF_0OxVCRIz&confirm=t&uuid=d8cf1231-a1b8-47db-98c7-87ec33f3444b\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip\n",
      "100%|██████████| 2.15G/2.15G [02:52<00:00, 12.5MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX\n",
      "From (redirected): https://drive.google.com/uc?id=1TOHalYk6aZQBOrg1PdPYzaHA0KlobgVX&confirm=t&uuid=df5ed501-d21b-4124-8f23-99997f848f18\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip\n",
      "100%|██████████| 2.15G/2.15G [02:51<00:00, 12.5MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46\n",
      "From (redirected): https://drive.google.com/uc?id=1QhdmWLFPdQFGI3myJ2QpxzT9rXp6cU46&confirm=t&uuid=fb12d525-4d7e-4462-8dcb-cdbaad4e0c15\n",
      "To: /workspace/ToxVidLM_ACL_2024/g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip\n",
      "100%|██████████| 1.65G/1.65G [02:08<00:00, 12.8MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip',\n",
       " 'g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip',\n",
       " 'g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download the entire folder (this works for some public folders)\n",
    "folder_id = \"1fddccfJkYZifbRF9zrhYlmX4IAMICnwb\"\n",
    "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=\"g_downloaded_data/\", quiet=False, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-001.zip...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-002.zip...\n",
      "Extracting g_downloaded_data/ToxVid/classification_final_data-20250630T215505Z-1-003.zip...\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "download_dir = \"g_downloaded_data/ToxVid\"\n",
    "# List all files in the download directory\n",
    "for filename in os.listdir(download_dir):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(download_dir, filename)\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(download_dir)      \n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv g_downloaded_data/ToxVid/classification_final_data final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acafed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_folder = \"final_data/classification_final_data\"\n",
    "destination_folder = \"final_data\"\n",
    "\n",
    "# Check if source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # List all files in the source folder\n",
    "    files = os.listdir(source_folder)\n",
    "    \n",
    "    # Move each file to the destination folder\n",
    "    for file in files:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(destination_folder, file)\n",
    "        shutil.move(source_path, destination_path)\n",
    "    \n",
    "    print(\"Files moved successfully.\")\n",
    "else:\n",
    "    print(\"Source folder does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09f3d3",
   "metadata": {},
   "source": [
    "# Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa13638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'final_data/' did not match any files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: pathspec 'g_downloaded_data/' did not match any files\n",
      "fatal: pathspec 'downloaded_data/' did not match any files\n"
     ]
    }
   ],
   "source": [
    "# Remove folders from Git tracking (but keep them locally)\n",
    "!git rm -r --cached final_data/\n",
    "!git rm -r --cached g_downloaded_data/\n",
    "!git rm -r --cached downloaded_data/\n",
    "!git rm -r --cached data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9917f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 521de73] Add data folders to .gitignore\n",
      " 3 files changed, 878 insertions(+)\n",
      " create mode 100644 .gitignore\n",
      " delete mode 100644 final_data/final_data.txt.txt\n",
      " create mode 100644 train_test.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Add the .gitignore changes\n",
    "!git add .gitignore\n",
    "\n",
    "# Commit the changes\n",
    "!git commit -m \"Add data folders to .gitignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c36b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Your descriptive commit message\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7529a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92235938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b15cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA memory allocation configuration to reduce fragmentation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5422f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# From train.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\"\n",
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:0\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final_data/final_processed_data_one_hot.csv\")\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.4, random_state=28703)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.4, random_state=28703)\n",
    "\n",
    "num_epochs = 1\n",
    "patience = 10\n",
    "batch_size = 2\n",
    "\n",
    "#for roberta\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"l3cube-pune/hing-roberta\")\n",
    "model = XLMRobertaModel.from_pretrained(\"l3cube-pune/hing-roberta\", torch_dtype=torch.float32)\n",
    "\n",
    "\n",
    "model = Multimodal_LLM(batch_size=batch_size, config=config, tokenizer=tokenizer, adapter_llm=model)\n",
    "\n",
    "train_ds = CustomDataset(dataframe=df_train, train=True, tokenizer=tokenizer)\n",
    "val_ds = CustomDataset(df_val, train=True, tokenizer=tokenizer)\n",
    "test_ds = CustomDataset(df_test, train=False, tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "\n",
    "train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea3dac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1 out of 2\n",
      "  0%|                                                   | 0/724 [00:00<?, ?it/s]thread '<unnamed>' panicked at /root/.cargo/registry/src/index.crates.io-6f17d22bba15001f/rayon-core-1.12.1/src/registry.rs:168:10:\n",
      "The global thread pool has not been initialized.: ThreadPoolBuildError { kind: IOError(Os { code: 11, kind: WouldBlock, message: \"Resource temporarily unavailable\" }) }\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n",
      "Process Process-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/data/dataset.py\", line 83, in __getitem__\n",
      "    sample = prepare_batch(batch=sample, tokenizer=self.tokenizer)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/data/utils.py\", line 148, in prepare_batch\n",
      "    tokenized_text = tokenizer(dialogue, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_len-3, add_special_tokens=False)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2798, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2904, in _call_one\n",
      "    return self.encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\", line 2977, in encode_plus\n",
      "    return self._encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\", line 576, in _encode_plus\n",
      "    batched_output = self._batch_encode_plus(\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/transformers/tokenization_utils_fast.py\", line 504, in _batch_encode_plus\n",
      "    encodings = self._tokenizer.encode_batch(\n",
      "pyo3_runtime.PanicException: The global thread pool has not been initialized.: ThreadPoolBuildError { kind: IOError(Os { code: 11, kind: WouldBlock, message: \"Resource temporarily unavailable\" }) }\n",
      "  0%|                                                   | 0/724 [00:07<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 506056) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 113, in <module>\n",
      "    train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 85, in train_model\n",
      "    train_loss = train_one_epoch(model, train_dataloader, optimizer, config)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 15, in train_one_epoch\n",
      "    for batch in tqdm(train_dataloader):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n",
      "RuntimeError: DataLoader worker (pid(s) 506056) exited unexpectedly\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0505f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Traceback (most recent call last):\n",
      "  File \"test.py\", line 112, in <module>\n",
      "    state_dict = torch.load(checkpoint_path, map_location=config.device)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 791, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 271, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/serialization.py\", line 252, in __init__\n",
      "    super().__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints/model_save.pth'\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331bf53",
   "metadata": {},
   "source": [
    "# For debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23a680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared. Available: 34072559616 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"GPU memory cleared. Available: {torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9565f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\"\n",
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10076c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save_path = config.results_directory + config.file_name + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "history={\"a\":\"b\"}\n",
    "with open(json_save_path, 'w') as json_file:\n",
    "    json.dump(history, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was cleaned up - the train_model function is already imported from iteration.py\n",
    "# No need to redefine it here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
