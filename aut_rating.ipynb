{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e8c787",
   "metadata": {},
   "source": [
    "# Some preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bd3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ToxVidLM_ACL_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38134eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4369ed7",
   "metadata": {},
   "source": [
    "## Packages Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0eef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn==0.12.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e48f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.0 (from -r requirements.txt (line 1))\n",
      "  Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.1 (from -r requirements.txt (line 2))\n",
      "  Downloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting torchaudio==2.0.1 (from -r requirements.txt (line 3))\n",
      "  Downloading torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting librosa==0.10.1 (from -r requirements.txt (line 4))\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting av==10.0.0 (from -r requirements.txt (line 5))\n",
      "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting opencv-python==4.8.1.78 (from -r requirements.txt (line 6))\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting Pillow==10.0.1 (from -r requirements.txt (line 7))\n",
      "  Downloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting tqdm==4.66.1 (from -r requirements.txt (line 8))\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy==1.24.4 (from -r requirements.txt (line 9))\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pandas==2.0.3 (from -r requirements.txt (line 10))\n",
      "  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting scikit-learn==1.3.2 (from -r requirements.txt (line 11))\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pytorchvideo==0.1.5 (from -r requirements.txt (line 12))\n",
      "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==4.35.2 (from -r requirements.txt (line 13))\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Collecting datasets==2.14.6 (from -r requirements.txt (line 14))\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate==0.4.1 (from -r requirements.txt (line 15))\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting filelock (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting sympy (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading networkx-3.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jinja2 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting requests (from torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting joblib>=0.14 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in ./.conda/lib/python3.8/site-packages (from librosa==0.10.1->-r requirements.txt (line 4)) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting soundfile>=0.12.1 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/lib/python3.8/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas==2.0.3->-r requirements.txt (line 10))\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.0.3->-r requirements.txt (line 10))\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.3.2->-r requirements.txt (line 11))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fvcore (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting parameterized (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
      "Collecting iopath (from pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading huggingface_hub-0.34.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from transformers==4.35.2->-r requirements.txt (line 13)) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyarrow>=8.0.0 (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting xxhash (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multiprocess-0.70.18-py38-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting responses<0.19 (from evaluate==0.4.1->-r requirements.txt (line 15))\n",
      "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (75.3.0)\n",
      "Requirement already satisfied: wheel in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (0.45.1)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 13))\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: importlib-metadata in ./.conda/lib/python3.8/site-packages (from numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (8.5.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./.conda/lib/python3.8/site-packages (from pooch>=1.0->librosa==0.10.1->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 10)) (1.16.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.1->-r requirements.txt (line 2))\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting yacs>=0.1.6 (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting termcolor>=1.1 (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting tabulate (from fvcore->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting portalocker (from iopath->pytorchvideo==0.1.5->-r requirements.txt (line 12))\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading multiprocess-0.70.17-py38-none-any.whl.metadata (7.2 kB)\n",
      "  Downloading multiprocess-0.70.16-py38-none-any.whl.metadata (7.1 kB)\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.1->-r requirements.txt (line 4))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.14.6->-r requirements.txt (line 14))\n",
      "  Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.conda/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa==0.10.1->-r requirements.txt (line 4)) (3.21.0)\n",
      "Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.0.1-cp38-cp38-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading aiohttp-3.10.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.1-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
      "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyarrow-17.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (746 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m746.5/746.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
      "Downloading frozenlist-1.5.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading yarl-1.15.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading propcache-0.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
      "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188686 sha256=29f5d0a7bef16f4bcb3cdb724c000b405ede5a2296fbf0f90e0d7bfca2562bf8\n",
      "  Stored in directory: /root/.cache/pip/wheels/84/62/e5/0b41f2deb978f449ba3efb4bb24efd6962e4b6abb1fae544ee\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61398 sha256=e272e7923cec1ce37780272c0a81d5267c84099f8b5ab644f00e956e4e520575\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=02ca7234796b98db8b0507c61dc33f76de5e346769d2619daa9802b151dbf9e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
      "Successfully built pytorchvideo fvcore iopath\n",
      "Installing collected packages: pytz, mpmath, lit, av, xxhash, urllib3, tzdata, tqdm, threadpoolctl, termcolor, tabulate, sympy, safetensors, regex, pyyaml, pycparser, propcache, portalocker, Pillow, parameterized, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, msgpack, MarkupSafe, llvmlite, lazy-loader, joblib, idna, hf-xet, fsspec, frozenlist, filelock, dill, cmake, charset_normalizer, certifi, audioread, attrs, async-timeout, aiohappyeyeballs, yarl, yacs, soxr, scipy, requests, pyarrow, pandas, opencv-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, numba, multiprocess, jinja2, iopath, cffi, aiosignal, soundfile, scikit-learn, responses, pooch, huggingface-hub, fvcore, aiohttp, tokenizers, pytorchvideo, librosa, transformers, datasets, evaluate, triton, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.0.1 aiohappyeyeballs-2.4.4 aiohttp-3.10.11 aiosignal-1.3.1 async-timeout-5.0.1 attrs-25.3.0 audioread-3.0.1 av-10.0.0 certifi-2025.7.14 cffi-1.17.1 charset_normalizer-3.4.2 cmake-4.0.3 datasets-2.14.6 dill-0.3.7 evaluate-0.4.1 filelock-3.16.1 frozenlist-1.5.0 fsspec-2023.10.0 fvcore-0.1.5.post20221221 hf-xet-1.1.5 huggingface-hub-0.34.1 idna-3.10 iopath-0.1.10 jinja2-3.1.6 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.1 lit-18.1.8 llvmlite-0.41.1 mpmath-1.3.0 msgpack-1.1.1 multidict-6.1.0 multiprocess-0.70.15 networkx-3.1 numba-0.58.1 numpy-1.24.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.8.1.78 pandas-2.0.3 parameterized-0.9.0 pooch-1.8.2 portalocker-3.0.0 propcache-0.2.0 pyarrow-17.0.0 pycparser-2.22 pytorchvideo-0.1.5 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 responses-0.18.0 safetensors-0.5.3 scikit-learn-1.3.2 scipy-1.10.1 soundfile-0.13.1 soxr-0.3.7 sympy-1.13.3 tabulate-0.9.0 termcolor-2.4.0 threadpoolctl-3.5.0 tokenizers-0.15.2 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 tqdm-4.66.1 transformers-4.35.2 triton-2.0.0 tzdata-2025.2 urllib3-2.2.3 xxhash-3.5.0 yacs-0.1.8 yarl-1.15.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212194fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft==0.6.2\n",
      "  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (25.0)\n",
      "Requirement already satisfied: psutil in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (2.0.0)\n",
      "Requirement already satisfied: transformers in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (4.35.2)\n",
      "Requirement already satisfied: tqdm in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (4.66.1)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.6.2)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in ./.conda/lib/python3.8/site-packages (from peft==0.6.2) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.conda/lib/python3.8/site-packages (from accelerate>=0.21.0->peft==0.6.2) (0.34.1)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./.conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.6.2) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.2) (75.3.0)\n",
      "Requirement already satisfied: wheel in ./.conda/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.2) (0.45.1)\n",
      "Requirement already satisfied: cmake in ./.conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.6.2) (4.0.3)\n",
      "Requirement already satisfied: lit in ./.conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.6.2) (18.1.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.conda/lib/python3.8/site-packages (from transformers->peft==0.6.2) (0.15.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.21.0->peft==0.6.2) (2023.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.21.0->peft==0.6.2) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft==0.6.2) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->transformers->peft==0.6.2) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft==0.6.2) (1.3.0)\n",
      "Downloading peft-0.6.2-py3-none-any.whl (174 kB)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.0.1 peft-0.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft==0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5468d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: backcall in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pickleshare in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7282c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.0\n",
      "Uninstalling torch-2.0.0:\n",
      "  Successfully uninstalled torch-2.0.0\n",
      "Found existing installation: torchvision 0.15.1\n",
      "Uninstalling torchvision-0.15.1:\n",
      "  Successfully uninstalled torchvision-0.15.1\n",
      "Found existing installation: torchaudio 2.0.1\n",
      "Uninstalling torchaudio-2.0.1:\n",
      "  Successfully uninstalled torchaudio-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu102\n",
      "Collecting torch==1.12.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torch-1.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.13.1+cu102\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.13.1%2Bcu102-cp38-cp38-linux_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.12.1\n",
      "  Downloading https://download.pytorch.org/whl/cu102/torchaudio-0.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch==1.12.1+cu102) (4.12.2)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (1.24.4)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (2.32.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (10.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2025.7.14)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.6.2 requires torch>=1.13.0, but you have torch 1.12.1+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.12.1+cu102 torchaudio-0.12.1+cu102 torchvision-0.13.1+cu102\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCUDA available: True\n",
      "CUDA version: 11.7\n",
      "PyTorch version: 2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "# Add this cell before the train cell\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu102\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c77d83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 10.2\n",
      "PyTorch version: 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09f3d3",
   "metadata": {},
   "source": [
    "# Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "105064d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ToxVidLM_ACL_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"final_data/\" >> .gitignore\n",
    "!echo \"g_downloaded_data/\" >> .gitignore\n",
    "!echo \"downloaded_data/\" >> .gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0c36b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"update the model to fit the final authenticity rating\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899956a",
   "metadata": {},
   "source": [
    "# Deal with our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509e3ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8802c9",
   "metadata": {},
   "source": [
    "## Download tiktok videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ed170ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a public folder, you can try:\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create download directory\n",
    "os.makedirs(\"g_video\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7c42e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1e8Z6S5hymxOAxXhAtrplsxwR-ahTecVS\n",
      "From (redirected): https://drive.google.com/uc?id=1e8Z6S5hymxOAxXhAtrplsxwR-ahTecVS&confirm=t&uuid=4064462c-f540-4b92-bd6a-33b4bcc7592e\n",
      "To: /workspace/g_video/downloaded_file.zip\n",
      "100%|██████████| 2.52G/2.52G [05:41<00:00, 7.39MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'g_video/downloaded_file.zip'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Direct download using the file ID\n",
    "file_id = \"1e8Z6S5hymxOAxXhAtrplsxwR-ahTecVS\"\n",
    "output_path = \"g_video/downloaded_file.zip\"\n",
    "\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294c07bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting g_video/downloaded_file.zip...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "download_dir = \"g_video\"\n",
    "# List all files in the download directory\n",
    "for filename in os.listdir(download_dir):\n",
    "    if filename.endswith(\".zip\") and filename==\"downloaded_file.zip\":\n",
    "        zip_path = os.path.join(download_dir, filename)\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(download_dir)      \n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bbb6a",
   "metadata": {},
   "source": [
    "## Start training with our new config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9288703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'XLMRobertaTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'XLMRobertaTokenizerFast'.\n",
      "You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 1 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:48<00:00,  5.36s/it]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:48<00:00,  5.36s/it]\n",
      "1.5718288156721327\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]1.5718288156721327\n",
      "100%|███████████████████████████████████████████| 17/17 [01:12<00:00,  4.29s/it]\n",
      "100%|███████████████████████████████████████████| 17/17 [01:12<00:00,  4.29s/it]\n",
      "authenticity   0.196078431372549   0.10527544351073766                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.95      0.32        19\n",
      "           3       0.40      0.05      0.09        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.20      0.08       100\n",
      "weighted avg       0.19      0.20      0.10       100\n",
      " \n",
      "\n",
      "authenticity   0.196078431372549   0.10527544351073766                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.95      0.32        19\n",
      "           3       0.40      0.05      0.09        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.20      0.08       100\n",
      "weighted avg       0.19      0.20      0.10       100\n",
      " \n",
      "\n",
      "Epoch 2 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 2 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:44<00:00,  4.91s/it]\n",
      "1.5735917621188693\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:44<00:00,  4.91s/it]\n",
      "1.5735917621188693\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.35s/it]\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.35s/it]\n",
      "authenticity   0.196078431372549   0.10527544351073766                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.95      0.32        19\n",
      "           3       0.40      0.05      0.09        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.20      0.08       100\n",
      "weighted avg       0.19      0.20      0.10       100\n",
      " \n",
      "\n",
      "Epoch 3 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]authenticity   0.196078431372549   0.10527544351073766                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.95      0.32        19\n",
      "           3       0.40      0.05      0.09        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.20      0.08       100\n",
      "weighted avg       0.19      0.20      0.10       100\n",
      " \n",
      "\n",
      "Epoch 3 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.00s/it]\n",
      "1.5696458684073553\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.00s/it]\n",
      "1.5696458684073553\n",
      "100%|███████████████████████████████████████████| 17/17 [01:12<00:00,  4.27s/it]\n",
      "authenticity   0.196078431372549   0.11087768440709618                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.18      0.89      0.30        19\n",
      "           3       0.43      0.08      0.13        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.19      0.09       100\n",
      "weighted avg       0.20      0.20      0.11       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:12<00:00,  4.27s/it]\n",
      "authenticity   0.196078431372549   0.11087768440709618                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.18      0.89      0.30        19\n",
      "           3       0.43      0.08      0.13        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.19      0.09       100\n",
      "weighted avg       0.20      0.20      0.11       100\n",
      " \n",
      "\n",
      "Epoch 4 out of 4\n",
      "Epoch 4 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:43<00:00,  4.86s/it]\n",
      "1.5689518981509738\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:43<00:00,  4.86s/it]\n",
      "1.5689518981509738\n",
      "100%|███████████████████████████████████████████| 17/17 [01:10<00:00,  4.17s/it]\n",
      "authenticity   0.196078431372549   0.12114845938375352                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.18      0.84      0.29        19\n",
      "           3       0.44      0.11      0.17        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.19      0.09       100\n",
      "weighted avg       0.20      0.20      0.12       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:10<00:00,  4.17s/it]\n",
      "authenticity   0.196078431372549   0.12114845938375352                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.18      0.84      0.29        19\n",
      "           3       0.44      0.11      0.17        38\n",
      "           4       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.12      0.19      0.09       100\n",
      "weighted avg       0.20      0.20      0.12       100\n",
      " \n",
      "\n",
      "saved best model with metric:  f1  for task:  authenticity\n",
      "saved best model with metric:  f1  for task:  authenticity\n",
      "Training finished!\n",
      "Epoch 1 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Training finished!\n",
      "Epoch 1 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:49<00:00,  5.55s/it]\n",
      "1.5603623257742987\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:49<00:00,  5.55s/it]\n",
      "1.5603623257742987\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "authenticity   0.21568627450980393   0.15536881419234363                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.80      0.30        20\n",
      "           3       0.50      0.17      0.26        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.22       100\n",
      "   macro avg       0.14      0.19      0.11       100\n",
      "weighted avg       0.21      0.22      0.15       100\n",
      " \n",
      "\n",
      "authenticity   0.21568627450980393   0.15536881419234363                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.80      0.30        20\n",
      "           3       0.50      0.17      0.26        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.22       100\n",
      "   macro avg       0.14      0.19      0.11       100\n",
      "weighted avg       0.21      0.22      0.15       100\n",
      " \n",
      "\n",
      "Epoch 2 out of 4\n",
      "Epoch 2 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.07s/it]\n",
      "1.5558616982565985\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.07s/it]\n",
      "1.5558616982565985\n",
      "100%|███████████████████████████████████████████| 17/17 [01:11<00:00,  4.19s/it]\n",
      "100%|███████████████████████████████████████████| 17/17 [01:11<00:00,  4.19s/it]\n",
      "authenticity   0.20588235294117646   0.16246498599439776                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.17      0.65      0.27        20\n",
      "           3       0.36      0.23      0.28        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.21       100\n",
      "   macro avg       0.11      0.18      0.11       100\n",
      "weighted avg       0.16      0.21      0.15       100\n",
      " \n",
      "\n",
      "authenticity   0.20588235294117646   0.16246498599439776                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.17      0.65      0.27        20\n",
      "           3       0.36      0.23      0.28        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.21       100\n",
      "   macro avg       0.11      0.18      0.11       100\n",
      "weighted avg       0.16      0.21      0.15       100\n",
      " \n",
      "\n",
      "Epoch 3 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 3 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:39<00:00,  4.44s/it]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:39<00:00,  4.44s/it]\n",
      "1.5530038409762912\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]1.5530038409762912\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "authenticity   0.22549019607843138   0.19056178026766263                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.60      0.27        20\n",
      "           3       0.34      0.31      0.33        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.23       100\n",
      "   macro avg       0.10      0.18      0.12       100\n",
      "weighted avg       0.16      0.23      0.17       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "authenticity   0.22549019607843138   0.19056178026766263                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.60      0.27        20\n",
      "           3       0.34      0.31      0.33        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.23       100\n",
      "   macro avg       0.10      0.18      0.12       100\n",
      "weighted avg       0.16      0.23      0.17       100\n",
      " \n",
      "\n",
      "Epoch 4 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 4 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.11s/it]\n",
      "1.5530374182595148\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:45<00:00,  5.11s/it]\n",
      "1.5530374182595148\n",
      "100%|███████████████████████████████████████████| 17/17 [01:13<00:00,  4.33s/it]\n",
      "authenticity   0.25000000000000006   0.2202769996887644                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.55      0.27        20\n",
      "           3       0.35      0.40      0.37        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.25       100\n",
      "   macro avg       0.11      0.19      0.13       100\n",
      "weighted avg       0.16      0.25      0.19       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:13<00:00,  4.33s/it]\n",
      "authenticity   0.25000000000000006   0.2202769996887644                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.18      0.55      0.27        20\n",
      "           3       0.35      0.40      0.37        35\n",
      "           4       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.25       100\n",
      "   macro avg       0.11      0.19      0.13       100\n",
      "weighted avg       0.16      0.25      0.19       100\n",
      " \n",
      "\n",
      "saved best model with metric:  f1  for task:  authenticity\n",
      "saved best model with metric:  f1  for task:  authenticity\n",
      "Training finished!\n",
      "Epoch 1 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Training finished!\n",
      "Epoch 1 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:47<00:00,  5.32s/it]\n",
      "1.5465849373075697\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:47<00:00,  5.32s/it]\n",
      "1.5465849373075697\n",
      "100%|███████████████████████████████████████████| 17/17 [01:13<00:00,  4.32s/it]\n",
      "authenticity   0.26470588235294124   0.21713352007469652                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.17      0.41      0.24        17\n",
      "           3       0.34      0.59      0.43        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.27       100\n",
      "   macro avg       0.10      0.20      0.13       100\n",
      "weighted avg       0.15      0.27      0.19       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:13<00:00,  4.32s/it]\n",
      "authenticity   0.26470588235294124   0.21713352007469652                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.17      0.41      0.24        17\n",
      "           3       0.34      0.59      0.43        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.27       100\n",
      "   macro avg       0.10      0.20      0.13       100\n",
      "weighted avg       0.15      0.27      0.19       100\n",
      " \n",
      "\n",
      "Epoch 2 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 2 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:44<00:00,  4.90s/it]\n",
      "1.5426580641004775\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:44<00:00,  4.90s/it]\n",
      "1.5426580641004775\n",
      "100%|███████████████████████████████████████████| 17/17 [01:15<00:00,  4.45s/it]\n",
      "authenticity   0.2745098039215687   0.22399626517273571                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.35      0.24        17\n",
      "           3       0.32      0.65      0.43        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.28       100\n",
      "   macro avg       0.10      0.20      0.14       100\n",
      "weighted avg       0.14      0.28      0.19       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:15<00:00,  4.45s/it]\n",
      "authenticity   0.2745098039215687   0.22399626517273571                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.19      0.35      0.24        17\n",
      "           3       0.32      0.65      0.43        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.28       100\n",
      "   macro avg       0.10      0.20      0.14       100\n",
      "weighted avg       0.14      0.28      0.19       100\n",
      " \n",
      "\n",
      "Epoch 3 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 3 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:48<00:00,  5.40s/it]\n",
      "1.5450392564137776\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:48<00:00,  5.40s/it]\n",
      "1.5450392564137776\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "authenticity   0.28431372549019607   0.21155462184873947                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.15      0.18      0.16        17\n",
      "           3       0.33      0.76      0.46        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.29       100\n",
      "   macro avg       0.10      0.19      0.12       100\n",
      "weighted avg       0.14      0.29      0.18       100\n",
      " \n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [01:14<00:00,  4.37s/it]\n",
      "authenticity   0.28431372549019607   0.21155462184873947                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.15      0.18      0.16        17\n",
      "           3       0.33      0.76      0.46        34\n",
      "           4       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.29       100\n",
      "   macro avg       0.10      0.19      0.12       100\n",
      "weighted avg       0.14      0.29      0.18       100\n",
      " \n",
      "\n",
      "Epoch 4 out of 4\n",
      "  0%|                                                     | 0/9 [00:00<?, ?it/s]Epoch 4 out of 4\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:47<00:00,  5.28s/it]\n",
      "1.5283284849590726\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:47<00:00,  5.28s/it]\n",
      "1.5283284849590726\n",
      " 12%|█████▏                                      | 2/17 [00:32<03:38, 14.58s/it]Process Process-187:\n",
      "Process Process-187:\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 322, in _worker_loop\n",
      "    data_queue.put((idx, data))\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 88, in put\n",
      "    self._start_thread()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 173, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/workspace/.conda/lib/python3.8/threading.py\", line 852, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 322, in _worker_loop\n",
      "    data_queue.put((idx, data))\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 88, in put\n",
      "    self._start_thread()\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 173, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/workspace/.conda/lib/python3.8/threading.py\", line 852, in start\n",
      "    _start_new_thread(self._bootstrap, ())\n",
      "RuntimeError: can't start new thread\n",
      " 12%|█████▏                                      | 2/17 [00:48<06:03, 24.23s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 181315) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train_tiktok.py\", line 122, in <module>\n",
      "    train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"authenticity\", \"f1\", devices=None)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 90, in train_model\n",
      "    val_metrics, _, _ = validate(model, val_dataloader, config)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 44, in validate\n",
      "    for batch in tqdm(val_dataloader):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n",
      "RuntimeError: DataLoader worker (pid(s) 181315) exited unexpectedly\n",
      " 12%|█████▏                                      | 2/17 [00:48<06:03, 24.23s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1133, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/queues.py\", line 107, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 424, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 181315) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train_tiktok.py\", line 122, in <module>\n",
      "    train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"authenticity\", \"f1\", devices=None)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 90, in train_model\n",
      "    val_metrics, _, _ = validate(model, val_dataloader, config)\n",
      "  File \"/workspace/ToxVidLM_ACL_2024/iteration.py\", line 44, in validate\n",
      "    for batch in tqdm(val_dataloader):\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 634, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1329, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1295, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/workspace/.conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1146, in _try_get_data\n",
      "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n",
      "RuntimeError: DataLoader worker (pid(s) 181315) exited unexpectedly\n"
     ]
    }
   ],
   "source": [
    "# Now training for authenticity instead of sentiment\n",
    "!python train_tiktok.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3bf9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/workspace/.conda/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'XLMRobertaTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'XLMRobertaTokenizerFast'.\n",
      "You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
      "You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "load state dict checkpoints/video_rating_authenticity__0.pth\n",
      "load state dict checkpoints/video_rating_authenticity__0.pth\n",
      "100%|███████████████████████████████████████████| 75/75 [03:27<00:00,  2.77s/it]\n",
      "authenticity   0.17   0.1033333333333333                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.16      0.92      0.28        51\n",
      "           3       0.29      0.03      0.06       121\n",
      "           4       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.17       300\n",
      "   macro avg       0.09      0.19      0.07       300\n",
      "weighted avg       0.14      0.17      0.07       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n",
      "100%|███████████████████████████████████████████| 75/75 [03:27<00:00,  2.77s/it]\n",
      "authenticity   0.17   0.1033333333333333                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.16      0.92      0.28        51\n",
      "           3       0.29      0.03      0.06       121\n",
      "           4       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.17       300\n",
      "   macro avg       0.09      0.19      0.07       300\n",
      "weighted avg       0.14      0.17      0.07       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n",
      "load state dict checkpoints/video_rating_authenticity__2.pth\n",
      "  0%|                                                    | 0/75 [00:00<?, ?it/s]load state dict checkpoints/video_rating_authenticity__2.pth\n",
      "100%|███████████████████████████████████████████| 75/75 [03:23<00:00,  2.71s/it]\n",
      "authenticity   0.27   0.2348888888888889                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        46\n",
      "           2       0.13      0.40      0.20        50\n",
      "           3       0.41      0.52      0.46       118\n",
      "           4       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.27       300\n",
      "   macro avg       0.11      0.18      0.13       300\n",
      "weighted avg       0.18      0.27      0.21       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n",
      "100%|███████████████████████████████████████████| 75/75 [03:23<00:00,  2.71s/it]\n",
      "authenticity   0.27   0.2348888888888889                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00        46\n",
      "           2       0.13      0.40      0.20        50\n",
      "           3       0.41      0.52      0.46       118\n",
      "           4       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.27       300\n",
      "   macro avg       0.11      0.18      0.13       300\n",
      "weighted avg       0.18      0.27      0.21       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n",
      "load state dict checkpoints/video_rating_authenticity__18.pth\n",
      "load state dict checkpoints/video_rating_authenticity__18.pth\n",
      "100%|███████████████████████████████████████████| 75/75 [03:14<00:00,  2.60s/it]\n",
      "100%|███████████████████████████████████████████| 75/75 [03:14<00:00,  2.60s/it]\n",
      "authenticity   0.3233333333333333   0.257079365079365                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.00      0.00      0.00        46\n",
      "           2       0.16      0.21      0.18        56\n",
      "           3       0.38      0.73      0.50       116\n",
      "           4       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.32       300\n",
      "   macro avg       0.11      0.19      0.14       300\n",
      "weighted avg       0.18      0.32      0.23       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n",
      "authenticity   0.3233333333333333   0.257079365079365                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.00      0.00      0.00        46\n",
      "           2       0.16      0.21      0.18        56\n",
      "           3       0.38      0.73      0.50       116\n",
      "           4       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.32       300\n",
      "   macro avg       0.11      0.19      0.14       300\n",
      "weighted avg       0.18      0.32      0.23       300\n",
      " \n",
      "\n",
      "\n",
      "Run with --save_predictions to save detailed results\n"
     ]
    }
   ],
   "source": [
    "!python test_tiktok.py "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
