{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e8c787",
   "metadata": {},
   "source": [
    "# Some preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8bd3c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/ToxVidLM_ACL_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38134eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install peft==0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5468d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77d83f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 10.2\n",
      "PyTorch version: 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2875312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.0.0\n",
      "Uninstalling torch-2.0.0:\n",
      "  Successfully uninstalled torch-2.0.0\n",
      "Found existing installation: torchvision 0.15.1\n",
      "Uninstalling torchvision-0.15.1:\n",
      "  Successfully uninstalled torchvision-0.15.1\n",
      "Found existing installation: torchaudio 2.0.1\n",
      "Uninstalling torchaudio-2.0.1:\n",
      "  Successfully uninstalled torchaudio-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu102\n",
      "Collecting torch==1.12.1+cu102\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torch-1.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (776.3 MB)\n",
      "Collecting torchvision==0.13.1+cu102\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchvision-0.13.1%2Bcu102-cp38-cp38-linux_x86_64.whl (19.1 MB)\n",
      "Collecting torchaudio==0.12.1\n",
      "  Using cached https://download.pytorch.org/whl/cu102/torchaudio-0.12.1%2Bcu102-cp38-cp38-linux_x86_64.whl (3.7 MB)\n",
      "Requirement already satisfied: typing-extensions in ./.conda/lib/python3.8/site-packages (from torch==1.12.1+cu102) (4.12.2)\n",
      "Requirement already satisfied: numpy in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (1.24.4)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (2.32.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.conda/lib/python3.8/site-packages (from torchvision==0.13.1+cu102) (10.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu102) (2025.7.14)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "peft 0.6.2 requires torch>=1.13.0, but you have torch 1.12.1+cu102 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.12.1+cu102 torchaudio-0.12.1+cu102 torchvision-0.13.1+cu102\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCUDA available: True\n",
      "CUDA version: 11.7\n",
      "PyTorch version: 2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "# Add this cell before the train cell\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==1.12.1+cu102 torchvision==0.13.1+cu102 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu102\n",
    "\n",
    "# Verify installation\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a3574",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793bc3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4242053",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir downloaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gdown first\n",
    "!pip install gdown\n",
    "\n",
    "# For a public folder, you can try:\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create download directory\n",
    "os.makedirs(\"downloaded_data\", exist_ok=True)\n",
    "\n",
    "# Download the entire folder (this works for some public folders)\n",
    "folder_id = \"1lAl6KpewLv9bO64Ad5fccBOImSZgRPPP\"\n",
    "gdown.download_folder(f\"https://drive.google.com/drive/folders/{folder_id}\", output=\"downloaded_data/\", quiet=False, use_cookies=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting downloaded_data/classification_final_data-20250630T215505Z-1-003.zip...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         zip_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, filename)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m     10\u001b[0m             zip_ref\u001b[38;5;241m.\u001b[39mextractall(download_dir)      \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraction complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/.conda/lib/python3.8/zipfile.py:1271\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1271\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1273\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/.conda/lib/python3.8/zipfile.py:1338\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "download_dir = \"downloaded_data\"\n",
    "# List all files in the download directory\n",
    "for filename in os.listdir(download_dir):\n",
    "    if filename.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(download_dir, filename)\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(download_dir)      \n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv downloaded_data/classification_final_data final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aa13638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_folder = \"final_data/classification_final_data\"\n",
    "destination_folder = \"final_data\"\n",
    "\n",
    "# Check if source folder exists\n",
    "if os.path.exists(source_folder):\n",
    "    # List all files in the source folder\n",
    "    files = os.listdir(source_folder)\n",
    "    \n",
    "    # Move each file to the destination folder\n",
    "    for file in files:\n",
    "        source_path = os.path.join(source_folder, file)\n",
    "        destination_path = os.path.join(destination_folder, file)\n",
    "        shutil.move(source_path, destination_path)\n",
    "    \n",
    "    print(\"Files moved successfully.\")\n",
    "else:\n",
    "    print(\"Source folder does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7529a",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92235938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Fri_Feb_21_20:23:50_PST_2025\n",
      "Cuda compilation tools, release 12.8, V12.8.93\n",
      "Build cuda_12.8.r12.8/compiler.35583870_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b15cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA memory allocation configuration to reduce fragmentation\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0505f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'test.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331bf53",
   "metadata": {},
   "source": [
    "# For debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c23a680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared. Available: 34072559616 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(f\"GPU memory cleared. Available: {torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bad24df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 4 commits.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   Untitled-1.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9565f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/ToxVidLM_ACL_2024/.conda/lib/python3.8/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\"\n",
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10076c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save_path = config.results_directory + config.file_name + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "history={\"a\":\"b\"}\n",
    "with open(json_save_path, 'w') as json_file:\n",
    "    json.dump(history, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, config, num_epochs, track_task, track_metric, devices=None):\n",
    "    \n",
    "    model = model.to(config.device)\n",
    "    history = {\"train_validation\": []}\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    best_val_metric = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1} out of {num_epochs}\")\n",
    "\n",
    "        # Training\n",
    "        train_loss = train_one_epoch(model, train_dataloader, optimizer, config)\n",
    "        \n",
    "        print(train_loss)\n",
    "\n",
    "        # Validation\n",
    "        val_metrics, _, _ = validate(model, val_dataloader, config)\n",
    "        \n",
    "        # print(val_metrics)\n",
    "\n",
    "        # Save metrics to history\n",
    "        epoch_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_metrics\": val_metrics\n",
    "        }\n",
    "        \n",
    "        history[\"train_validation\"].append(epoch_data)\n",
    "        \n",
    "        json_save_path = config.results_directory + config.file_name + \".json\"\n",
    "\n",
    "        # Save to JSON file\n",
    "        with open(json_save_path, 'w') as json_file:\n",
    "            json.dump(history, json_file)\n",
    "        \n",
    "        \n",
    "        if val_metrics[track_task][track_metric] > best_val_metric:\n",
    "            best_val_metric = val_metrics[track_task][track_metric]\n",
    "            # torch.save(model.state_dict(), config.directory + config.file_name + \".pth\")\n",
    "\n",
    "    \n",
    "    print(\"Training finished!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c143c749",
   "metadata": {},
   "source": [
    "# Old ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9614102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "source_folder = \"final_data/classification_final_data\"\n",
    "destination_folder = \"final_data\"\n",
    "\n",
    "# List all files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Move each file to the destination folder\n",
    "for file in files:\n",
    "    source_path = os.path.join(source_folder, file)\n",
    "    destination_path = os.path.join(destination_folder, file)\n",
    "    shutil.move(source_path, destination_path)\n",
    "\n",
    "print(\"Files moved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"final_data/final_processed_data_one_hot.csv\")\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.1, random_state=28703)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.1, random_state=28703)\n",
    "\n",
    "num_epochs = 30\n",
    "patience = 10\n",
    "batch_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d9b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#for roberta\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"l3cube-pune/hing-roberta\")\n",
    "model = XLMRobertaModel.from_pretrained(\"l3cube-pune/hing-roberta\", torch_dtype=torch.float32)\n",
    "\n",
    "#for gpt2\n",
    "# tokenizer = PreTrainedTokenizerFast.from_pretrained('l3cube-pune/hing-gpt')\n",
    "# model = GPT2Model.from_pretrained('l3cube-pune/hing-gpt', torch_dtype=torch.float32)\n",
    "# tokenizer.bos_token_id = 1\n",
    "# tokenizer.eos_token_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a6b4ea7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Multimodal_LLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMultimodal_LLM\u001b[49m(batch_size\u001b[38;5;241m=\u001b[39mbatch_size, config\u001b[38;5;241m=\u001b[39mconfig, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, adapter_llm\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      3\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m CustomDataset(dataframe\u001b[38;5;241m=\u001b[39mdf_train, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m      4\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m CustomDataset(df_val, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Multimodal_LLM' is not defined"
     ]
    }
   ],
   "source": [
    "model = Multimodal_LLM(batch_size=batch_size, config=config, tokenizer=tokenizer, adapter_llm=model)\n",
    "\n",
    "train_ds = CustomDataset(dataframe=df_train, train=True, tokenizer=tokenizer)\n",
    "val_ds = CustomDataset(df_val, train=True, tokenizer=tokenizer)\n",
    "test_ds = CustomDataset(df_test, train=False, tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, num_workers=16)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb6330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5c125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, config, devices)\u001b[0m\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/toxvid/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/model/model.py:73\u001b[0m, in \u001b[0;36mMultimodal_LLM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 73\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#ids\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     bos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([batch_size, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "train_one_epoch(model, train_dataloader, optimizer, config, devices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4aaa46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffensive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:84\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, config, num_epochs, track_task, track_metric, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_loss)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, config, devices)\u001b[0m\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/toxvid/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/model/model.py:73\u001b[0m, in \u001b[0;36mMultimodal_LLM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 73\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#ids\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     bos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([batch_size, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
