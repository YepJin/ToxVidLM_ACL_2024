{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a006977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json)\\ done\n",
      "Solving environment: done\n",
      "Solving environment: done\n",
      "done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/miniconda3/envs/toxvid\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.8\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.16-h5eee18b_0 \n",
      "  pip                pkgs/main/linux-64::pip-24.2-py38h06a4308_0 \n",
      "  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "  python             pkgs/main/linux-64::python-3.8.20-he870216_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.14-h993c535_1 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0 \n",
      "  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: / \n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /root/miniconda3/envs/toxvid\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.8\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
      "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
      "  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
      "  openssl            pkgs/main/linux-64::openssl-3.0.16-h5eee18b_0 \n",
      "  pip                pkgs/main/linux-64::pip-24.2-py38h06a4308_0 \n",
      "  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n",
      "  python             pkgs/main/linux-64::python-3.8.20-he870216_0 \n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
      "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py38h06a4308_0 \n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
      "  tk                 pkgs/main/linux-64::tk-8.6.14-h993c535_1 \n",
      "  wheel              pkgs/main/linux-64::wheel-0.44.0-py38h06a4308_0 \n",
      "  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n",
      "  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n",
      "  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n",
      "  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n",
      "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Executing transaction: done\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate toxvid\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate toxvid\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create --name toxvid python=3.8 -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cd0a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda activate toxvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e48f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.0 (from -r requirements.txt (line 1))\n",
      "  Using cached torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.1 (from -r requirements.txt (line 2))\n",
      "  Using cached torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting torchaudio==2.0.1 (from -r requirements.txt (line 3))\n",
      "  Using cached torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting librosa (from -r requirements.txt (line 4))\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: av in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (12.3.0)\n",
      "Collecting opencv-python (from -r requirements.txt (line 6))\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.24.4)\n",
      "Requirement already satisfied: pandas in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (2.0.3)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 11))\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pytorchvideo in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.1.5)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (4.46.3)\n",
      "Requirement already satisfied: datasets in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (3.1.0)\n",
      "Requirement already satisfied: evaluate in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.4.4)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Collecting sympy (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch==2.0.0->-r requirements.txt (line 1)) (3.1)\n",
      "Collecting jinja2 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torchvision==0.15.1->-r requirements.txt (line 2)) (2.32.4)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (75.1.0)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 1)) (0.44.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa->-r requirements.txt (line 4))\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting numba>=0.51.0 (from librosa->-r requirements.txt (line 4))\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting scipy>=1.6.0 (from librosa->-r requirements.txt (line 4))\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "Collecting joblib>=1.0 (from librosa->-r requirements.txt (line 4))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 4)) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa->-r requirements.txt (line 4))\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa->-r requirements.txt (line 4))\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->-r requirements.txt (line 4))\n",
      "  Downloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa->-r requirements.txt (line 4))\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->-r requirements.txt (line 4))\n",
      "  Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 10)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 10)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 10)) (2025.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 11))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fvcore in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pytorchvideo->-r requirements.txt (line 12)) (0.1.5.post20221221)\n",
      "Requirement already satisfied: parameterized in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pytorchvideo->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: iopath in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pytorchvideo->-r requirements.txt (line 12)) (0.1.10)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (0.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->-r requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 14)) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 14)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 14)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 14)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 14)) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 14)) (3.10.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 14)) (5.0.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers->-r requirements.txt (line 13)) (1.1.5)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.0->librosa->-r requirements.txt (line 4))\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting importlib-metadata (from numba>=0.51.0->librosa->-r requirements.txt (line 4))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 4)) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->torchvision==0.15.1->-r requirements.txt (line 2)) (2025.6.15)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa->-r requirements.txt (line 4))\n",
      "  Downloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: yacs>=0.1.6 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from fvcore->pytorchvideo->-r requirements.txt (line 12)) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from fvcore->pytorchvideo->-r requirements.txt (line 12)) (2.4.0)\n",
      "Requirement already satisfied: tabulate in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from fvcore->pytorchvideo->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: portalocker in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from iopath->pytorchvideo->-r requirements.txt (line 12)) (3.0.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.0->-r requirements.txt (line 1))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 4))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->-r requirements.txt (line 14)) (0.2.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata->numba>=0.51.0->librosa->-r requirements.txt (line 4))\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading torch-2.0.0-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.15.1-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.0.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
      "Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Downloading soxr-0.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
      "Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading cmake-4.0.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: mpmath, lit, zipp, threadpoolctl, sympy, soxr, scipy, pycparser, opencv-python, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, msgpack, MarkupSafe, llvmlite, lazy_loader, joblib, cmake, audioread, scikit-learn, pooch, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, importlib-metadata, cffi, soundfile, numba, librosa, triton, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 audioread-3.0.1 cffi-1.17.1 cmake-4.0.3 importlib-metadata-8.5.0 jinja2-3.1.6 joblib-1.4.2 lazy_loader-0.4 librosa-0.11.0 lit-18.1.8 llvmlite-0.41.1 mpmath-1.3.0 msgpack-1.1.1 numba-0.58.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-4.11.0.86 pooch-1.8.2 pycparser-2.22 scikit-learn-1.3.2 scipy-1.10.1 soundfile-0.13.1 soxr-0.3.7 sympy-1.13.3 threadpoolctl-3.5.0 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0 zipp-3.20.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d2144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (10.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca137a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (5.9.1)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (2.0.0)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from peft) (0.33.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (1.1.5)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.44.0)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (4.0.3)\n",
      "Requirement already satisfied: lit in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (18.1.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from transformers->peft) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/toxvid/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
      "Downloading accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-1.0.1 peft-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdd7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "/root/miniconda3/envs/toxvid/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import AddedToken\n",
    "from transformers import CLIPModel, VideoMAEModel, Wav2Vec2Model, VideoMAEConfig, CLIPConfig, Wav2Vec2Config, XLMRobertaConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSeq2SeqLM\n",
    "from model.additional_modules import LSTM_fc, FC_head, Gate_Attention\n",
    "from argparse import Namespace \n",
    "from model.model import Multimodal_LLM\n",
    "from data.dataset import CustomDataset\n",
    "from iteration import train_model, train_one_epoch, validate\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, AlbertTokenizer, XLMRobertaTokenizerFast, PreTrainedTokenizerFast #only for gpt2 and assign values\n",
    "from transformers import GPT2Model, BertModel, AlbertModel, XLMRobertaModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2711eeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "tasks_bool = {\"offensive\" : True, \"offensive_level\": True, \"sentiment\" : True}\n",
    "tasks = []\n",
    "name = \"gpt2_vidmae_whisper_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9614102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "source_folder = \"final_data/classification_final_data\"\n",
    "destination_folder = \"final_data\"\n",
    "\n",
    "# List all files in the source folder\n",
    "files = os.listdir(source_folder)\n",
    "\n",
    "# Move each file to the destination folder\n",
    "for file in files:\n",
    "    source_path = os.path.join(source_folder, file)\n",
    "    destination_path = os.path.join(destination_folder, file)\n",
    "    shutil.move(source_path, destination_path)\n",
    "\n",
    "print(\"Files moved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a93e2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in tasks_bool.items():\n",
    "    if tasks_bool[k]:\n",
    "        tasks.append(k)\n",
    "        name += k + \"_\"\n",
    "        \n",
    "config = Namespace(\n",
    "    file_name=name + \"0\",\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "    tokenizer_path=\"ckpts\",\n",
    "    tasks = tasks,\n",
    "    offensive_bool = tasks_bool[\"offensive\"],\n",
    "    offensive_level_bool = tasks_bool[\"offensive_level\"],\n",
    "    sentiment_bool = tasks_bool[\"sentiment\"],\n",
    "    video_encoder=\"MCG-NJU/videomae-base\",\n",
    "    audio_encoder=\"openai/whisper-small\",\n",
    "    lstm_or_conv = False,\n",
    "    image_conv_kernel=23,\n",
    "    image_conv_stride=3,\n",
    "    image_conv_padding=8,\n",
    "    video_conv_kernel=36,\n",
    "    video_conv_stride=24,\n",
    "    video_conv_padding=0,\n",
    "    audio_conv_kernel=50,\n",
    "    audio_conv_stride=23,\n",
    "    audio_conv_padding=1,\n",
    "    llm_embed_dim=768,\n",
    "    llm_output_dim=768,\n",
    "    attn_dropout=0.1,\n",
    "    is_add_bias_kv=True,\n",
    "    is_add_zero_attn=True,\n",
    "    attention_heads=8,\n",
    "    image_dim=768,\n",
    "    video_dim=768,\n",
    "    audio_dim=768,\n",
    "    image_seq_len=197,\n",
    "    video_seq_len=1568,\n",
    "    audio_seq_len=1500,\n",
    "    min_mm_seq_len=64,\n",
    "    lstm_num_layers=1,\n",
    "    tokenizer_max_len=128,\n",
    "    add_pooling = False,\n",
    "    train=True,\n",
    "    directory = \"checkpoints/\",\n",
    "    results_directory = \"results/\"\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"final_data/final_processed_data_one_hot.csv\")\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.1, random_state=28703)\n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.1, random_state=28703)\n",
    "\n",
    "num_epochs = 30\n",
    "patience = 10\n",
    "batch_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at l3cube-pune/hing-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#for roberta\n",
    "tokenizer = XLMRobertaTokenizerFast.from_pretrained(\"l3cube-pune/hing-roberta\")\n",
    "model = XLMRobertaModel.from_pretrained(\"l3cube-pune/hing-roberta\", torch_dtype=torch.float32)\n",
    "\n",
    "#for gpt2\n",
    "# tokenizer = PreTrainedTokenizerFast.from_pretrained('l3cube-pune/hing-gpt')\n",
    "# model = GPT2Model.from_pretrained('l3cube-pune/hing-gpt', torch_dtype=torch.float32)\n",
    "# tokenizer.bos_token_id = 1\n",
    "# tokenizer.eos_token_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a6b4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multimodal_LLM(batch_size=batch_size, config=config, tokenizer=tokenizer, adapter_llm=model)\n",
    "\n",
    "train_ds = CustomDataset(dataframe=df_train, train=True, tokenizer=tokenizer)\n",
    "val_ds = CustomDataset(df_val, train=True, tokenizer=tokenizer)\n",
    "test_ds = CustomDataset(df_test, train=False, tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, num_workers=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, batch_size=batch_size, num_workers=16)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=batch_size, num_workers=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb6330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf5c125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, config, devices)\u001b[0m\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/toxvid/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/model/model.py:73\u001b[0m, in \u001b[0;36mMultimodal_LLM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 73\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#ids\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     bos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([batch_size, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "train_one_epoch(model, train_dataloader, optimizer, config, devices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4aaa46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1628 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moffensive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:84\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, config, num_epochs, track_task, track_metric, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_loss)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/iteration.py:18\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, config, devices)\u001b[0m\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {key: value\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/toxvid/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ToxVidLLM_ACL_2024/model/model.py:73\u001b[0m, in \u001b[0;36mMultimodal_LLM.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 73\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m#ids\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     bos \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([batch_size, \u001b[38;5;241m1\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbos_token_id\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image'"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, config, num_epochs, \"offensive\", \"f1\", devices=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
